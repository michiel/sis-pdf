# 20260201 Triage Workplan

## Goal
Translate the "next steps" roadmap into a sequenced checklist that can be executed across the core scanner, detectors, and documentation so emergent primitives, canonicalisation, action telemetry, and reader-context scoring land together with corresponding QA hooks.

## Steps
1. **Establish canonicalisation metadata** ✅
   - Define the canonical view that detectors should consume, including normalized name resolution, canonical filter chains, and incremental-update deduplication. Implement the pass inside `sis_pdf_core`, expose the canonical indices via the scan context, and document the metadata emitted (e.g., # of incremental versions stripped, filters rewritten).
   - Add regression/fixture tests feeding obfuscated PDFs to ensure the canonical view stabilises object ordering and filter naming.
   - Surface canonicalisation signals in the structural summary and ensure downstream components (report generator, CLI) can report the diff for transparency.
2. **Extend findings/report schema with telemetry** *(schema updated, detectors/docs pending)*
   - Add `action_type`, `action_target`, `action_initiation`, and `reader_impacts` fields to `sis_pdf_core::model::Finding` and ensure they are serialized and surfaced by all report formats (`Report`, JSON/Text outputs, CLI queries).
   - Update existing action and embedded file detectors to populate the new fields using `annotate_action_meta`; expose reader-impact metadata beyond the current `reader.impact.*` hashes (e.g., a `reader_impacts` list summarizing impacts with profile names).
   - Update documentation (`docs/findings.md` and query docs) to describe how to read the new fields and what values they carry.
3. **Reader-context scoring enhancements** *(in progress: reader impacts emitted, reporting pending)*
   - Expand `reader_context` so it emits a structured map or list per finding, describing how severity/impact/attack surface shift for Acrobat, PDFium, and Preview.
   - Use those entries when constructing reports so the CLI and JSON outputs can reference the same metadata without recomputing the mapping, and document the scoring logic.
4. **Emerging primitive heuristics and metadata**
   - Inventory the CVEs referenced in `plans/20260201-next-steps.md` and `docs/research/202602-pdf-attack-surface-breakdown.md` (gvar, JBIG2 chains, zero-click imagery) and assign them to detectors (`font_analysis`, `image_analysis`, `filter_chain_anomaly`, etc.).
   - Implement semantic heuristics that produce clear CVE metadata (e.g., gvar glyph-count mismatches with CVE=2025-27363, filter chain JBIG2+ASCII with CVE references). Ensure each heuristic emits `meta` entries for the CVE ID and matched attack surface category.
   - Add fixtures/tests covering each primitive and assert the detectors emit the expected metadata with canonicalisation and reader scoring in place.
5. **Validation, docs, and cadence**
   - Update `plans/20260201-threat-intel-cadence.md` to mention the automation refresh, daily/weekly sign-offs, and release-note hooks introduced earlier.
   - Ensure `docs/threat-intel-tracker.md` includes the CVEs we plan to cover and annotate each row with owner, severity, impact, confidence, and linked tests.
   - Link the fixtures/detectors to the tracker entries so triage steps and CI coverage remain visible for every new heuristic.

## Considerations
- Treat any automation changes or new detectors as needing regression tests and docs updates before completion.
- Coordinate reader-impact metadata with the CLI output (e.g., `sis query findings` should expose the new fields) and ensure no existing pipelines break when canonical indices shift.
- Keep an eye on rate limits and idempotency when re-running the CVE automation as part of this effort; use the new plan to tie the workflow to weekly triage.

## Next actions & design choices

1. **Centralise `Finding` construction** – introduce a helper that provides default `impact`, `reader_impacts`, and `action_*` fields so every detector, test, and runner path can focus on supply the variable bits (surface/kind/severity/confidence/meta). This avoids repetitive `..` blocks and makes future schema tweaks easier.
2. **Cover the expanded `Confidence` space** – `Certain`, `Tentative`, and `Weak` now exist, so update every match/scoring switch (reports, `features_extended`, `ir_enhanced`, heuristics) to handle them. Choose scoring values that align with existing severity buckets and keep a consistent `as_str()` mapping for CLI output.
3. **Document & expose the telemetry** – once the code emits `reader_impacts`, `impact`, and action metadata consistently, update `docs/findings.md` and the query/text outputs to describe the new fields (including the human-readable summary inserted into `reader.impact.summary`) so analysts can rely on the enriched reports.
4. **Resume subsequent plan items** – after the schema work and docs surface, continue with the remaining steps above (emerging primitives, fixtures, tracker automation) to keep the triage cadence aligned with the research-driven threats.
